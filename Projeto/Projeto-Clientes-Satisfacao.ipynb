{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Academy\n",
    "\n",
    "# Prevendo o Nível de Satisfação dos Clientes do Santander\n",
    "\n",
    "### Gustavo Ferrara Ataulo Zampieri\n",
    "\n",
    "### 27/05/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Descrição\n",
    "Para este projeto será utilizada a linguagem Python. Os datasets do projeto estão disponíveis no <!--(link) --> [Kaggle](https://www.kaggle.com/c/santander-customer-satisfaction).\n",
    "A satisfação de clientes é uma medida fundamental de sucesso. O **Banco Santander** está pedindo para ajudá-los a identificar clientes insatisfeitos no início do relacionamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Objetivo\n",
    "\n",
    "Definir o problema de negócio, fazer a coleta e preparo dos dados, escolher um algoritmo, treine o modelo e avalie a acurácia, que deve ser de **pelo menos 70%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Definindo Problema de Negócio\n",
    "\n",
    "Prever se um cliente está satisfeito ou insatisfeito através de sua experiência bancária."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Coleta\n",
    "\n",
    "Carregando os datasets de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino = pd.read_csv(\"dados/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0     2     23                 0.0                      0.0   \n",
       "1     2     34                 0.0                      0.0   \n",
       "2     2     23                 0.0                      0.0   \n",
       "3     2     37                 0.0                    195.0   \n",
       "4     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  imp_op_var40_ult1  ...  \\\n",
       "0                      0.0                      0.0                0.0  ...   \n",
       "1                      0.0                      0.0                0.0  ...   \n",
       "2                      0.0                      0.0                0.0  ...   \n",
       "3                      0.0                      0.0                0.0  ...   \n",
       "4                      0.0                      0.0                0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando as primeiras linhas\n",
    "df_treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 371)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a dimensão do dataset\n",
    "df_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                           int64\n",
       "var3                         int64\n",
       "var15                        int64\n",
       "imp_ent_var16_ult1         float64\n",
       "imp_op_var39_comer_ult1    float64\n",
       "                            ...   \n",
       "saldo_medio_var44_hace3    float64\n",
       "saldo_medio_var44_ult1     float64\n",
       "saldo_medio_var44_ult3     float64\n",
       "var38                      float64\n",
       "TARGET                       int64\n",
       "Length: 371, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando os tipos de dados\n",
    "df_treino.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como não foi disponibilizado o significado das variáveis deste dataset, passamos para a etapa de pré-processamento dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tratamento nos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta etapa é muito importante, pois é realizada limpeza nos dados, para evitar ao máximo possíveis erros e valores outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sumarização dos dados\n",
    "df_treino.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>2.716483</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>9.447971</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID          var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000  76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723      2.716483     33.212865           86.208265   \n",
       "std     43781.947379      9.447971     12.956486         1614.757313   \n",
       "min         1.000000      0.000000      5.000000            0.000000   \n",
       "25%     38104.750000      2.000000     23.000000            0.000000   \n",
       "50%     76043.000000      2.000000     28.000000            0.000000   \n",
       "75%    113748.750000      2.000000     40.000000            0.000000   \n",
       "max    151838.000000    238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veja que a variável \"var3\" possui como valor minimo 999999.000000, isto claramente é um outlier, vamos deixar com valor 2.0\n",
    "# já que 75% dos dados possuem este valor.\n",
    "df_treino[\"var3\"].replace(-999999,2,inplace=True)\n",
    "df_treino.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76020, 370)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminando a coluna ID\n",
    "df_treino = df_treino.drop(\"ID\", axis = 1)\n",
    "df_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4841"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando se existe valores duplicados\n",
    "df_treino.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71179, 370)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo valores duplicados\n",
    "df_treino = df_treino.drop_duplicates()\n",
    "df_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando se existem valores NA\n",
    "df_treino.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c2800974a8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualização gráfica da variável target\n",
    "sns.countplot(data = df_treino, x = \"TARGET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível verificar que a variável target está totalmente desbalanceada, isto é, existe uma diferença muito grande entre clientes insatisfeitos (0) e clientes satisfeitos (1). Fazendo uma acurácia dos dados, é possíver ver que ela será extremamente alta justamente por conta deste desbalanceamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia nos Dados de Teste: 95.977%\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "X = df_treino.iloc[:,0:369]\n",
    "Y = df_treino.iloc[:,369]\n",
    "\n",
    "# Definindo o tamanho das amostras\n",
    "teste_size = 0.3\n",
    "\n",
    "# Garante que os resultados podem ser reproduzidos\n",
    "# Isso é importante para comparar a acurácia com outros algoritmos de Machine Learning.\n",
    "seed = 7\n",
    "\n",
    "# Criando os conjuntos de dados de treino e de teste\n",
    "X_treino, X_teste, Y_treino, Y_teste = train_test_split(X, Y, test_size = teste_size, random_state = seed)\n",
    "\n",
    "# Criação do modelo\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Treinamento do modelo\n",
    "modelo.fit(X_treino, Y_treino)\n",
    "\n",
    "# Score do modelo nos dados de teste\n",
    "result = modelo.score(X_teste, Y_teste)\n",
    "print(\"Acurácia nos Dados de Teste: %.3f%%\" % (result * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para tratar isto, vamos usar a função SMOTE.\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SM = SMOTE(random_state = 2)\n",
    "X_treino_smoted, Y_treino_smoted = SM.fit_resample(X_treino, Y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c283054f28>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verificando a variável target após o balanceamento.\n",
    "sns.countplot(Y_treino_smoted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validando novamente um teste de acurácia no conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 50.016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Definindo valores para o número de folds\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "\n",
    "# Separando os dados em folds\n",
    "kfold = KFold(num_folds, True, random_state = seed)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Cross-Validation\n",
    "resultado = cross_val_score(modelo, X_treino_smoted, Y_treino_smoted, cv = kfold, scoring = 'accuracy')\n",
    "\n",
    "# Print dos resultados\n",
    "print(\"Acurácia: %.3f\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que obtivemos uma acurácia de 50%, ainda está longe do objetivo que é de no mínimo 70%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa, é importante realizar transformações nas variáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizaremos agora a **Normalização dos Dados**, que tem como objetivo colocar os dados em um range de 0 à 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados Originais: \n",
      "\n",
      " [[2.0000000e+00 2.3000000e+01 0.0000000e+00 ... 0.0000000e+00\n",
      "  3.9205170e+04 0.0000000e+00]\n",
      " [2.0000000e+00 3.4000000e+01 0.0000000e+00 ... 0.0000000e+00\n",
      "  4.9278030e+04 0.0000000e+00]\n",
      " [2.0000000e+00 2.3000000e+01 0.0000000e+00 ... 0.0000000e+00\n",
      "  6.7333770e+04 0.0000000e+00]\n",
      " ...\n",
      " [2.0000000e+00 3.9000000e+01 0.0000000e+00 ... 0.0000000e+00\n",
      "  1.1863452e+05 0.0000000e+00]\n",
      " [2.0000000e+00 2.3000000e+01 0.0000000e+00 ... 0.0000000e+00\n",
      "  7.4028150e+04 0.0000000e+00]\n",
      " [2.0000000e+00 2.5000000e+01 0.0000000e+00 ... 0.0000000e+00\n",
      "  8.4278160e+04 0.0000000e+00]]\n",
      "\n",
      "Dados Normalizados: \n",
      "\n",
      " [[0.00851064 0.33333333 0.         ... 0.         0.         0.00629279]\n",
      " [0.00851064 0.19191919 0.         ... 0.         0.         0.00845535]\n",
      " [0.00851064 0.19191919 0.         ... 0.         0.         0.00710396]\n",
      " [0.00851064 0.18181818 0.         ... 0.         0.         0.00596996]\n",
      " [0.00851064 0.56565657 0.         ... 0.         0.         0.00556702]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Normalizando os dados\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "rescaledX = scaler.fit_transform(X_treino_smoted)\n",
    "\n",
    "# Sumarizando os dados transformados\n",
    "print(\"Dados Originais: \\n\\n\", df_treino.values)\n",
    "print(\"\\nDados Normalizados: \\n\\n\", rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Algoritmos de Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando algoritmo de **Regressão Logística** após a normalização dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 73.028\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Definindo valores para o número de folds\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "\n",
    "# Separando os dados em folds\n",
    "kfold = KFold(num_folds, True, random_state = seed)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Cross-Validation\n",
    "resultado_logistic_regression = cross_val_score(modelo, rescaledX, Y_treino_smoted, cv = kfold, scoring = 'accuracy')\n",
    "\n",
    "# Criando lista para salvar resultados de modelos\n",
    "resultados_modelos = []\n",
    "nome = []\n",
    "\n",
    "# Salvando resultado na lista\n",
    "resultados_modelos.append(resultado_logistic_regression)\n",
    "nome.append(\"LR\")\n",
    "\n",
    "# Print dos resultados\n",
    "print(\"Acurácia: %.3f\" % (resultado_logistic_regression.mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando **Linear Discriminant Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 72.409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Separando os dados em folds\n",
    "kfold = KFold(num_folds, True, random_state = seed)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Cross Validation\n",
    "resultado_LDA = cross_val_score(modelo, rescaledX, Y_treino_smoted, cv = kfold)\n",
    "\n",
    "# Salvando na lista\n",
    "resultados_modelos.append(resultado_LDA)\n",
    "nome.append(\"LDA\")\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia: %.3f\" % (resultado_LDA.mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Seleção do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando os modelos com uma representação gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Boxplot para comparar os algoritmos\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Comparação de Algoritmos de Classificação')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(resultados_modelos)\n",
    "ax.set_xticklabels(nome)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível perceber que o algoritmo de classificação **Regressão Logística** obteve melhor acurácia (73.028%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Salvando o Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo!\n",
      "Modelo carregado!\n",
      "Acurácia: 95.397\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "# Criando o modelo\n",
    "modelo = LogisticRegression()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(rescaledX, Y_treino_smoted)\n",
    "\n",
    "# Salvando o modelo\n",
    "arquivo = 'modelos/modelo_classificador_final.sav'\n",
    "pickle.dump(modelo, open(arquivo, 'wb'))\n",
    "print(\"Modelo salvo!\")\n",
    "\n",
    "# Carregando o arquivo\n",
    "modelo_classificador_final = pickle.load(open(arquivo, 'rb'))\n",
    "modelo_prod = modelo_classificador_final.score(X_teste, Y_teste)\n",
    "print(\"Modelo carregado!\")\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia: %.3f\" % (modelo_prod.mean() * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
